{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Extract features</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import required libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os # reading data\n",
    "import cv2 # reading images\n",
    "import pickle as cpickle # store data for fast processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Setup the proper locations for the datasets folders</h3>\n",
    "<p>Dataset can be found <a href=\"https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\">here</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataDir = \"...\\\\train\"\n",
    "testDataDir = \"...\\\\test\"\n",
    "validateDataDir = \"...\\\\val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Initialize dictionaries in which we will store the data of each category</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {}\n",
    "testing_data = {}\n",
    "validate_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"NORMAL\", \"PNEUMONIA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extract data using KAZE descriptor function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Kaze_features(image):\n",
    "    try:\n",
    "        alg = cv2.KAZE_create()\n",
    "        # Dinding image keypoints\n",
    "        kps = alg.detect(image)\n",
    "        # Getting first 32 of them.\n",
    "        # Number of keypoints is varies depend on image size and color pallet\n",
    "        # Sorting them based on keypoint response value(bigger is better)\n",
    "        vector_size = 32\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        # computing descriptors vector\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        # Flatten all of them in one big vector - our feature vector\n",
    "        dsc = dsc.flatten()\n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less the 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "        return dsc\n",
    "    except cv2.error as e:\n",
    "        print('Error: ' + e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extract data using HOG descriptor function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Hog_Features(image):\n",
    "    try:\n",
    "        cell_size = (8, 8)  # h x w in pixels\n",
    "        block_size = (2, 2)  # h x w in cells\n",
    "        nbins = 9  # number of orientation bins\n",
    "\n",
    "        # winSize is the size of the image cropped to an multiple of the cell size\n",
    "        hog = cv2.HOGDescriptor(_winSize=(image.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                          image.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                                _blockSize=(block_size[1] * cell_size[1],\n",
    "                                            block_size[0] * cell_size[0]),\n",
    "                                _blockStride=(cell_size[1], cell_size[0]),\n",
    "                                _cellSize=(cell_size[1], cell_size[0]),\n",
    "                                _nbins=nbins)\n",
    "\n",
    "        n_cells = (image.shape[0] // cell_size[0], image.shape[1] // cell_size[1])\n",
    "        dsc = hog.compute(image) \\\n",
    "            .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                     n_cells[0] - block_size[0] + 1,\n",
    "                     block_size[0], block_size[1], nbins) \\\n",
    "            .transpose((1, 0, 2, 3, 4))\n",
    "        return dsc.flatten()\n",
    "    except cv2.error as e:\n",
    "        print('Error: ' + e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generic function for feature extraction</h3>\n",
    "<p>Function needs as parameters:\n",
    "<ol>\n",
    "  <li>Image path</li>\n",
    "  <li>Descriptor (Empty, KAZE, HOG)</li>\n",
    "</ol>\n",
    "Returns an array.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path, extractFeaturesUsing = ''):\n",
    "    # make sure that image is grayscale\n",
    "    image_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # resize image to 100'100\n",
    "    image = cv2.resize(image_array, (100, 100))\n",
    "    if extractFeaturesUsing == '':\n",
    "        return image.flatten()\n",
    "    elif extractFeaturesUsing == 'KAZE':\n",
    "        return Get_Kaze_features(image)\n",
    "    elif extractFeaturesUsing == 'HOG':\n",
    "        return Get_Hog_Features(image)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load data function</h3>\n",
    "<p>Function needs as parameters:\n",
    "<ol>\n",
    "  <li>Dictionary that we are trying to construct (one of the three we initialized at the start).</li>\n",
    "  <li>Directory location.</li>\n",
    "  <li>Name of pickle in which we will store the data for fast access.</li>\n",
    "  <li>Descriptor with which we will extract the features (None, KAZE, HOG).</li>\n",
    "</ol>\n",
    "After the load function finishes, stores the dictionary into a pickle file and so we are now able to load the data again really fast.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(dictionaryToStoreData, dataDir, pickleName, extractFeaturesUsing = ''):\n",
    "    # load training data\n",
    "    for category in categories:\n",
    "        path = os.path.join(dataDir, category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            name = img.split('/')[-1].lower()\n",
    "            try:\n",
    "                imageLocation = os.path.join(path, img)\n",
    "                features = extract_features(imageLocation, extractFeaturesUsing)\n",
    "                dictionaryToStoreData[imageLocation] = [features, class_num]\n",
    "            except:\n",
    "                print(\"An exception occurred while extracting features from image \" + name)\n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open(pickleName + '.pickle', 'wb') as fp:\n",
    "        cpickle.dump(dictionaryToStoreData, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Example of LoadData use </h3>\n",
    "<p> Load data using HOG descriptor</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoadData(training_data, trainDataDir, 'trainingDataUsingHog', 'HOG')\n",
    "LoadData(testing_data, testDataDir, 'testingDataUsingHog', 'HOG')\n",
    "LoadData(validate_data, validateDataDir, 'validateDataUsingHog', 'HOG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
